{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(experiment, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(3,4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Linear(4,3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = experiment()\n",
    "net2 = experiment()\n",
    "net3 = experiment()\n",
    "\n",
    "for params in net.parameters():\n",
    "    nn.init.normal_(params, mean=0, std=0.01)\n",
    "    \n",
    "net2.load_state_dict(net.state_dict())\n",
    "net3.load_state_dict(net.state_dict())\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1 fc2.weight\n",
      "tensor([[-0.0088,  0.0113, -0.0019, -0.0041],\n",
      "        [ 0.0077, -0.0197, -0.0020,  0.0086],\n",
      "        [ 0.0085, -0.0064, -0.0003,  0.0042]])\n",
      "net2 fc2.weight\n",
      "tensor([[-0.0088,  0.0113, -0.0019, -0.0041],\n",
      "        [ 0.0077, -0.0197, -0.0020,  0.0086],\n",
      "        [ 0.0085, -0.0064, -0.0003,  0.0042]])\n",
      "net3 fc2.weight\n",
      "tensor([[-0.0088,  0.0113, -0.0019, -0.0041],\n",
      "        [ 0.0077, -0.0197, -0.0020,  0.0086],\n",
      "        [ 0.0085, -0.0064, -0.0003,  0.0042]])\n"
     ]
    }
   ],
   "source": [
    "print('net1 fc2.weight')\n",
    "print(net.state_dict()['fc2.weight'])\n",
    "print('net2 fc2.weight')\n",
    "print(net2.state_dict()['fc2.weight'])\n",
    "print('net3 fc2.weight')\n",
    "print(net3.state_dict()['fc2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func2 = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=0.1)\n",
    "optimizer3 = optim.SGD(net3.parameters(), lr=0.1)"
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_rule(net, loss_func, optimizer, data, labels, PI):\n",
    "    student_outputs = net(data) # outputs->[]    \n",
    "    # print(student_outputs)\n",
    "    student_loss = loss_func(student_outputs, labels.squeeze())\n",
    "    teacher_loss = loss_func2(student_outputs, student_outputs*math.exp(0.5))\n",
    "    loss = (1-PI) * student_loss + PI * teacher_loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(net.state_dict()['fc2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_norule(net, loss_func, optimizer, data, labels):\n",
    "    student_outputs = net(data) # outputs->[]    \n",
    "    loss = loss_func(student_outputs, labels.squeeze()) # input(N,C) where C= number of classes Target(N)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(net.state_dict()['fc2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1 fc2.weight\n",
      "tensor([[-0.0088,  0.0114, -0.0019, -0.0041],\n",
      "        [ 0.0077, -0.0197, -0.0020,  0.0086],\n",
      "        [ 0.0085, -0.0065, -0.0004,  0.0042]])\n",
      "net2 fc2.weight\n",
      "tensor([[-0.0087,  0.0115, -0.0019, -0.0040],\n",
      "        [ 0.0076, -0.0198, -0.0020,  0.0085],\n",
      "        [ 0.0085, -0.0066, -0.0004,  0.0042]])\n",
      "net3 fc2.weight\n",
      "tensor([[-0.0087,  0.0115, -0.0019, -0.0040],\n",
      "        [ 0.0076, -0.0198, -0.0020,  0.0085],\n",
      "        [ 0.0085, -0.0066, -0.0004,  0.0042]])\n"
     ]
    }
   ],
   "source": [
    "x_input = torch.randn(50, 3)\n",
    "y_target = torch.empty(50, dtype=torch.long).random_(3)\n",
    "print('net1 fc2.weight')\n",
    "train_with_rule(net, loss_func, optimizer, x_input, y_target, 0.8)\n",
    "print('net2 fc2.weight')\n",
    "train_with_norule(net2, loss_func, optimizer2, x_input, y_target)\n",
    "print('net3 fc2.weight')\n",
    "train_with_norule(net3, loss_func, optimizer3, x_input, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
